#!/usr/bin/env python
"""
%prog [options]
Tomoki Isogai (isogait@carleton.edu)
   
"""

from __future__ import division

import os
import sys
import optparse
import glob
import cPickle
import time
import numpy
import shutil
from pylal import metaarray

try:
    import sqlite3
except ImportError:
   # pre 2.5.x
   from pysqlite2 import dbapi2 as sqlite3

from pylal import KW_veto_utils
from pycoh import iopycoh


__author__ = "Tomoki Isogai <isogait@carleton.edu>"
__version__ = "1.0"

def parse_commandline():
    """
    Parse the options given on the command-line.
    """
    parser = optparse.OptionParser(usage=__doc__,version=__version__)
    parser.add_option("-r", "--result_dir", default = "results",
                      help="Result files from pycoh in pickle. Required.")
    parser.add_option("-o", "--out_name", default = "result.db",\
        help="Output file name. (Default: result.db)")
    parser.add_option("-t", "--threshold", type="float",
                      help="Threshold for significant lines. This value times sigma will be used as a threshold.")
    parser.add_option("-w", "--web_link",
                      help="Web link address. Ex. https://ldas-jobs.ligo.caltech.edu/~detchar/S6/LineSearch/H1_COH_937612815_938217615_webpage/channelPages/")
    parser.add_option("-s", "--scratch_dir", default=".",
                      help="Scratch directory to be used for database engine. Specify local scratch directory for better performance and less file server load.")
    parser.add_option("-v", "--verbose", action="store_true",\
                      default=False, help="Run verbosely.")
    
    opts, args = parser.parse_args()
    
    if opts.threshold is None:
         print >> sys.stderr, "Error: --threshold is a required parameter"
         sys.exit(1)

    # make an output directory if it doesn't exist yet
    out_dir = os.path.split(opts.out_name)[0]
    if not os.path.exists(out_dir) and out_dir != "": os.makedirs(out_dir)
        
    # show parameters
    if opts.verbose:
        print >> sys.stderr, ""
        print >> sys.stderr, "running db_maker..."
        print >> sys.stderr, "version: %s"%__version__
        print >> sys.stderr, ""
        print >> sys.stderr, "***************** PARAMETERS ********************"
        for o in opts.__dict__.items():
          print >> sys.stderr, o[0]+":"
          print >> sys.stderr, o[1]
        print >> sys.stderr, ""
        
    return opts

def find_channel_name(channel):
  """
  find channel name from pycoh output file name
  """
  # get rid of path and extension if exists
  channel = os.path.splitext(os.path.basename(channel))[0]
  name_parts = channel.split("_",1)[1].split("+")[-1].split("-")
  ifo = name_parts[0].split(":")[0]
  channel =  "-".join(name_parts[:2])
  gps_time = (int(name_parts[2]),int(name_parts[2])+int(name_parts[3].split(".")[0]))
  return ifo, channel, gps_time

def rename(src):
  """
  If src alaready exists, this function rename it so that new file/directory
   won't overwite
  """
  index = 0; dst = os.path.normpath(src)
  while os.path.exists(dst):
    index += 1
    dst = "%s.%d"%(os.path.normpath(src),index)
  if index > 0:
    print >> sys.stderr, "Warning: %s already exists, renaming the existing one to %s and continuing..."%(src,dst)
    os.renames(src,dst)


def exclude_harmonics(ff, harmonics, width):
    """
    create a boolean array which contains False for frequencies around integer
    multible of harmonics around the width specified, True otherwise
    """
    good_freq = numpy.array(len(ff)*[True],bool)
    har = int(ff[0]/harmonics)+harmonics
    wid = width
    for i in range(len(ff)):
        if ff[i] > har - wid:
            if ff[i] < har + wid:
                good_freq[i] = False
            else:
                har += harmonics
                wid += width

    return good_freq

def cluster_lines(sig_ff,sig_coh):
  """
  """
  start_f = sig_ff[0]
  end_f = sig_ff[0]
  peak_f = sig_ff[0]
  max_coh = sig_coh[0]
  cluster = []
  for f, c in sorted(zip(sig_ff,sig_coh)):
    if f - end_f <= df * 50:
      end_f = f
      if max_coh < c:
        peak_f = f
        max_coh = c
    else:
      cluster.append((start_f,peak_f,end_f,max_coh))
      start_f = f
      end_f = f
      peak_f = f
      max_coh = c
  # get the last one
  cluster.append((start_f,peak_f,end_f,max_coh))

  return cluster

def save_lines():
  """
  Find significant lines, cluster and print them to txt file, sorted by
  frequency.
  This returns line at peak, in a form:
  (start freq, peak freq, end freq, coherence)
  """
  # list significant lines
  #sig_lines = significance[good_freq][above_thresh[good_freq]].tolist()
  sig_freqs = ff[eff_index][coh[eff_index]>thresh].tolist()
  sig_cohs = coh[eff_index][coh[eff_index]>thresh].tolist()

  # cluster
  if len(sig_freqs)>0:
    cluster = cluster_lines(sig_freqs, sig_cohs)
    sorted_cluster = sorted(cluster,reverse=True,cmp=lambda x,y:cmp(x[3],y[3]))
  else:
    cluster = []
    sorted_cluster = []

  if opts.web_link is None:
    link = ""
  else:
    link = os.path.join(opts.web_link,"%s.html"%channel)

  print link

  for f in cluster:
    cursor.execute('insert into result values (?, ?, ?, ?, ?, ?, ?, ?, ?)',(channel,f[0],f[1],f[2],f[3],gps_time[0],gps_time[1],'',link))

  connection.commit()


def find_coincident(structure,df,result_dict):
  """
  if there is overlap, coincident
  """
  coinc = {}
  for r in result_dict:
    for c in result_dict[r]['cluster']:
      if structure[0] < c[2] + 2 * df and c[0] - df * 2 < structure[2]:
        coinc[r] = c
        break
  return coinc


# =============================================================================
#
#                                   MAIN
#
# =============================================================================
  

## parse commandline
opts = parse_commandline()

coh_list = [os.path.join(opts.result_dir,f) for f in os.listdir(opts.result_dir) if f.find("COH") != -1]
if True:
  rename(opts.out_name)
  working_filename = KW_veto_utils.get_connection_filename(\
                     opts.out_name,tmp_path=opts.scratch_dir,verbose=opts.verbose)
  connection = sqlite3.connect(working_filename)
  cursor = connection.cursor()
  cursor.execute('create table result (channel text, lowFreq double, peakFreq double, highFreq double, significance double, startTime int, endTime int, comments text, link text)')
  
  
  for coh_f in coh_list:
    if opts.verbose: 
      print >> sys.stderr, "gathering info from %s"%coh_f
    # get info
    coh_data = iopycoh.load_dict(coh_f)

    coh = abs(coh_data['coh'])**2
    ff = coh_data['ff']
    #f = open("/home/nathaniel.strauss/coh1test.txt",'w')
    #for i in coh:
    #    f.write(str(i) +"\n")
    #f.close()
    if isinstance(coh_data['coh'], metaarray.Spectrum):
      df = coh_data['coh'].metadata.df
      Tchunks = coh_data['Tchunks']
      #window_length = [int(o.split()[1]) for o in coh_data['coh'].metadata.comments[0].split("--") if (o.startswith('window-length-seconds'))][0]
      #min_ff = ff[0]
      #max_ff = ff[-1]
      
      # figure out 1/N level (expectation value for coherence)
      N = Tchunks * df # * window_length
      inv_N = 1 / N
      thresh = inv_N * opts.threshold
      # make sure it's below 1, otherwise use 0.95 (arbitrary high value)
      thresh = thresh < 1 and thresh or 0.95
      
      
      # exclude 60 harmonics
      #no_harm = exclude_harmonics(ff, 60, 0.1)
      #eff_index = (ff > opts.min_ff) & (ff < opts.max_ff) & no_harm
    
      eff_index = (ff > 0) # just index; do nothing
    
      ifo, channel, gps_time = find_channel_name(coh_f)
    
      # save the data
      if opts.verbose:
        print >> sys.stderr, "saving data / prominent lines..."
      save_lines()
    else:
      print >> sys.stderr, "HERE2"
      print >> sys.stderr, coh_data['coh']
  connection.commit()
  connection.close()
  print >> sys.stderr, "moving %s to %s..."%(working_filename,opts.out_name)
  shutil.copy(working_filename,opts.out_name)

#finally:
#  # erase temporal database
#  if globals().has_key('working_filename'):
#    db = globals()["working_filename"]
#    if opts.verbose:
#      print >> sys.stderr, "removing temporary workspace '%s'..." % db
#    os.remove(db)

print >> sys.stderr, "Done!"
