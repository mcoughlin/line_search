#!/usr/bin/python
"""
%prog -i ini_file [options]

Tomoki Isogai (isogait@carleton.edu)

This program parses param file, sets up a segment file, and creates dag file.

$Id: KW_veto_setup,v 1.6 2008/12/06 06:57:09 isogait Exp $
"""
# =============================================================================
#
#                               PREAMBLE
#
# =============================================================================

import os
import sys
import optparse
import ConfigParser
import glob
import re
import shutil
import time
import urllib2
import numpy as np

from glue import pipeline
from glue import segmentsUtils
from glue.segments import segment, segmentlist
from glue.iterutils import *

from pylal import KW_veto_utils

__author__ = "Tomoki Isogai <isogait@carleton.edu>"
__date__ = "$08/01/2009"
__version__ = "1.0"

def parse_commandline():
    """
    Parse the options given on the command-line.
    """
    parser = optparse.OptionParser(usage=__doc__,version=__version__)

    parser.add_option("-i", "--ini_file", help="file which contains parameters")
    parser.add_option("-v", "--verbose", action="store_true",\
                      default=False, help="run verbosely")
    
    # parse the options
    opts, args = parser.parse_args()
    
    # check if necessary input exists
    if opts.ini_file is None:
      print >>sys.stderr, "--%s is a required parameter"%opts.ini_file
      sys.exit(1)
    if not os.path.isfile(opts.ini_file):
      print >>sys.stderr, "ini file not found"
      sys.exit(1)    
        
    return opts

################################################################################
# Define Jobs.  A Job corresponds to a program.  Each Job can have multiple 
# Nodes (instances).
################################################################################

class lineSearchJob(pipeline.CondorDAGJob):
  def __init__(self, cp):
    """
    cp = a ConfigParser instance
    """
    self.__executable = cp.get('condor','line_search-bin')
    self.__universe = "vanilla"
    pipeline.CondorDAGJob.__init__(self,self.__universe, self.__executable)

    self.set_stdout_file('logs/$(logname)-$(cluster).out')
    self.set_stderr_file('logs/$(logname)-$(cluster).err')
    self.add_condor_cmd('getenv','True')
    self.add_condor_cmd('accounting_group',cp.get("condor", "accounting_group"))

    self.add_opt("result_dir",cp.get("output","out_dir"))
    self.add_opt("out_dir",web_outdir)
    self.add_opt("segfile",segment_file)
    self.add_opt("threshold",cp.get("data_conditioning","threshold"))
    self.add_opt("param_file",opts.ini_file)
    self.add_opt("pycoh_param",cp.get("input","pycoh_ini"))
    self.add_arg("--verbose")

class dbMakerJob(pipeline.CondorDAGJob):
  def __init__(self, cp):
    """
    cp = a ConfigParser instance
    """
    self.__executable = cp.get('condor','db_maker-bin')
    self.__universe = "vanilla"
    pipeline.CondorDAGJob.__init__(self,self.__universe, self.__executable)

    self.set_stdout_file('logs/$(logname)-$(cluster).out')
    self.set_stderr_file('logs/$(logname)-$(cluster).err')
    self.add_condor_cmd('getenv','True')
    self.add_condor_cmd('accounting_group',cp.get("condor", "accounting_group"))

    self.add_opt("result_dir",cp.get("output","out_dir"))
    self.add_opt("out_name",os.path.join(cp.get("output","out_dir"),cp.get("general","tag")+".db"))
    self.add_opt("threshold",cp.get("data_conditioning","threshold"))
    link = os.path.join(cp.get("webpage","web_link"),"%s_webpage"%cp.get("general","tag"),"channelPages")
    self.add_opt("web_link",link)
    self.add_opt("scratch_dir",cp.get("condor","scratchdir"))
    self.add_arg("--verbose")
        
################################################################################
# Define Nodes.  A Node corresponds to a single instance of a program to be
# run.  They each attach to a Job, which contains the information common to
# all Nodes of a single type.
################################################################################

class lineSearchNode(pipeline.CondorDAGNode):
  def __init__(self, job, name, retry, filePrefix):
    """
    """
    
    pipeline.CondorDAGNode.__init__(self, job)

    self.set_name(name)
    self.set_retry(retry)
    self.add_macro("logname","lineSearch-"+filePrefix) # used for log name

class dbMakerNode(pipeline.CondorDAGNode):
  def __init__(self, job, name, retry, filePrefix):
    """
    """
    
    pipeline.CondorDAGNode.__init__(self, job)

    self.set_name(name)
    self.set_retry(retry)
    self.add_macro("logname","dbMaker-"+filePrefix) # used for log name
        
################################################################################
# Manipulate segment files and get the actual segments to run the program on
################################################################################

def get_analyze_segment():
  """
  cp is a config parser instance

  This function does the following to get the segment list to be analyzed:
  - take a union of the segment files specified on analyzed_seg_files 
    in param file
  - subtract category specified 
  """
  if opts.verbose: print "making segment list..."

  if not os.path.exists("segfiles"): os.makedirs("segfiles")
  
  ################# take a union of analyzed_seg_files ######################
  
  if opts.verbose: print "getting analyzed segments..."
  analyzed_seg_files = KW_veto_utils.get_files_from_globs(cp.get("input","analyzed_seg_files"))
  # check if there is at least one file
  if analyzed_seg_files == []:
      print >>sys.stderr, "Error: analyzed_seg_files not found."
      sys.exit(1)
      
  if opts.verbose: print "added seg files:", analyzed_seg_files
  analyzed_segs=segmentlist()
  # take a union of one segment list at a time
  for fileName in analyzed_seg_files:
    if fileName.endswith("txt"):
      segs = KW_veto_utils.read_segfile(fileName)
    elif fileName.endswith("xml") or fileName.endswith("xml.gz"):
      segs = KW_veto_utils.read_segfile_xml(fileName,opts.verbose)
    else:
      print >> sys.stderr, "Error: file format of %s is not supported."%fileName
      sys.exit(1)
    analyzed_segs.__ior__(segs)
  
  ####################### subtract flag_seg_files ########################
 
  if opts.verbose: print "subtracting flag_seg_files..." 
  flag_seg_files = KW_veto_utils.get_files_from_globs(cp.get("input","flag_seg_files")) 
  if opts.verbose: print "subtracted seg files:",flag_seg_files
  for fileName in flag_seg_files:
    if fileName.endswith("txt"):
      segs = KW_veto_utils.read_segfile(fileName)
    elif fileName.endswith("xml") or fileName.endswith("xml.gz"):
      segs = KW_veto_utils.read_segfile_xml(fileName)
    else:
      print >> sys.stderr, "Error: file format of %s is not supported."%fileName
      sys.exit(1)
    analyzed_segs = analyzed_segs - segs

  analyzed_segs.coalesce()

  ######################### subtract category times ######################

  if any(cats.values()) == True:
    start = int(analyzed_segs[0][0])
    end = int(analyzed_segs[-1][1]+1)
    duration = end - start
    # FIXME: write my own function - ligolw_segments_from_cats gets segments 
    # for all ifos and wasteful
    def get_cats():
      if opts.verbose:
        print "getting cat veto files..."
        print "this might take a while..."
      cmd = "ligolw_segments_from_cats --veto-file %s --output-dir %s --segment-url %s --separate-categories --gps-start-time %d --gps-end-time %d"%(cp.get("input","veto_definer_file"),"segfiles",cp.get("input","server"),start,end)
      exit = os.system(cmd)
      if exit > 0:
        print >> sys.stderr, """
        Error: command below failed.
               %s"""%cmd
        sys.exit(1)

    for i in cats.keys():
      if cats[i] == True:
        cat_file = "segfiles/%s-VETOTIME_CAT%d-%d-%d.xml"%(cp.get("input","ifo"),i,start,duration)  
        if not os.path.isfile(cat_file):
          get_cats()
        if opts.verbose: print "subtracting %s"%cat_file  
        analyzed_segs = analyzed_segs - KW_veto_utils.read_segfile_xml(cat_file,opts.verbose)

  analyzed_segs.coalesce()
  if opts.verbose: 
      print "segs to be analyzed:"; print analyzed_segs

  # for name
  start_time = int(analyzed_segs[0][0])
  end_time = int(analyzed_segs[-1][1])
  duration = end_time - start_time      

  ########################### save the result ############################
  
  output_name = os.path.join("segfiles","%s-%s-%s-%s-segs.txt"%(cp.get("general","tag"),cp.get("input","ifo"),str(start_time),str(duration)))
  if opts.verbose: print "saving the segment list in %s..."%output_name
  segmentsUtils.tosegwizard(open(output_name,"w"),analyzed_segs)
  return start_time, duration, output_name

###############################################################################
# Overwrite pycoh ini file
###############################################################################

def write_pycoh_ini(ifo, tag, pycoh_ini, filename, segfile, chanlist, scratchDir):
  """
  """
  curTime = time.strftime('%m-%d-%Y %H:%M:%S',time.localtime())
  user = os.environ['USER']
  ini = []
  for line in open(pycoh_ini).readlines():
    if line.startswith("; id:"):
      line = "; id: %s: %s\n"%(curTime,user)
    if line.startswith("tag"):
      line = "tag = %s\n"%tag
    if line.startswith("analyzable-segments"):
      line = "analyzable-segments = %s\n"%(segfile)
    if line.startswith("chanlist1"):
#      line = "chanlist1 = %s:LSC-DARM_ERR\n"%ifo
#      line = "chanlist1 = %s:ALS-Y_ETM_LONG_IN1_DQ\n"%ifo
#      line = "chanlist1 = %s:ALS-Y_ARM_IN1_DQ\n"%ifo
#      line = "chanlist1 = %s:OAF-CAL_DARM_DQ\n"%ifo
      line = "chanlist1 = %s:GDS-CALIB_STRAIN\n"%ifo
    if line.startswith("chanlist2"):
      line = "chanlist2 = %s\n"%(",".join(chanlist))
    if line.startswith("frametype1"):
      line = "frametype1 = %s_HOFT_C00\n"%(ifo)
    if line.startswith("frametype2"):
      line = "frametype2 = %s_R\n"%(ifo)
    if line.startswith("scratchdir"):
      line = "scratchdir = %s\n"%scratchDir

    ini.append(line)

  open(filename,'w').write("".join(ini))

def run_seed(tag,ini_file,working_dir):
  """
  """
  original_dir = os.path.abspath(os.curdir)
  try:
    os.chdir(working_dir)
    cmd = "%s -sdDFHPi %s"%(cp.get("condor","pycoh_seed-bin"),os.path.abspath(ini_file))
    print cmd
    exit = os.system(cmd)
    dagfile = os.path.join(os.path.abspath(working_dir),tag+".dag")
    if exit > 0 or not os.path.isfile(dagfile):
      print >> sys.stderr, "Error: seed failed:"
      print >> sys.stderr, cmd
      sys.exit(1)
    condor_no_submit_dag(dagfile)
  finally:
    os.chdir(original_dir)
  
def condor_no_submit_dag(dagFile):
  """
  """
  cmd = "condor_submit_dag -no_submit -maxjobs 100 -f %s"%dagFile
  exit = os.system(cmd)
  subfile = dagFile + ".condor.sub"
  if exit > 0 or not os.path.isfile(subfile):
    print >> sys.stderr, "Error: condor_submit_dag failed:"
    print >> sys.stderr, cmd
    sys.exit(1)
  

################################################################################
# Set up DAG 
################################################################################

def dag_maker(pycoh_job_num):
    """
    This function creates a dag file and condor submission files
    
    ifo_list contains ifos on which vetoStats is to run (vetoStats is the 
    program that calculates all the necessary values of veto like 
    used percentage, veto efficiency, dead time percentage etc.)
    ifo_list=[] means no vetoStats (use results from a previous run)
    cp is a config parser instance
    """
    tag = cp.get("general", "tag")
    ifo = cp.get("input", "ifo")

    ## create directory for Condor output and error files
    KW_veto_utils.rename("logs") 
    os.mkdir("logs")

    ############################################################################
    # set dag
    ############################################################################
    
    dag=pipeline.CondorDAG(os.path.join(cp.get("condor","logdir"),"%s.log"%tag))
    dag.set_dag_file(os.path.join("dags",tag))  

    ############################################################################
    # set jobs and subfiles
    ############################################################################
    
    lineSearch_job = lineSearchJob(cp)
    lineSearch_job.set_sub_file(os.path.join("dags","%s.lineSearch.sub"%tag))
    dbMaker_job = dbMakerJob(cp)
    dbMaker_job.set_sub_file(os.path.join("dags","%s.dbMaker.sub"%tag))
    
    ############################################################################
    # set each node
    ############################################################################
    
    retry = cp.getint("condor","retry")
    
    # channel_list is the list of channels to be analyzed 

    pycoh_parent = [] # to be used to define dependancies of nodes    
    for n in range(pycoh_job_num):
      n += 1
      pycoh_tag = "%s_pycoh_%d"%(cp.get("general","tag"),n)
      pycohJob = pipeline.CondorDAGManJob("%s.dag"%pycoh_tag,pycoh_tag)
      pycohNode = pipeline.CondorDAGNode(pycohJob)
      pycohNode.set_retry(retry)
      pycohNode.set_post_script(cp.get("condor","post_pycoh-bin"))
      pycohNode.add_post_script_arg("$RETURN %s"%os.path.abspath(cp.get("output","out_dir")))
      dag.add_node(pycohNode)
      pycoh_parent.append(pycohNode)

       
    filePrefix = "-".join([cp.get("general","tag"),ifo,str(start_time),str(duration)])
    dagNodeName = "dbMaker"
    db = dbMakerNode(dbMaker_job,dagNodeName,retry,filePrefix)
    # add parent
    for p in pycoh_parent:
      db.add_parent(p)
    db.set_post_script(cp.get("condor","post_db_maker-bin"))
    db.add_post_script_arg("$RETURN %s"%os.path.abspath(cp.get("output","out_dir")))
    dag.add_node(db)
    dbMaker_job.write_sub_file()

    dagNodeName = "lineSearch"
    ls = lineSearchNode(lineSearch_job,dagNodeName,retry,filePrefix)
    # add parent
    ls.add_parent(db)
    dag.add_node(ls)
    lineSearch_job.write_sub_file()
      
    # output workflow as DAG or script; assumes that parents always appear
    # before children.
    dag.write_dag()
    
# =============================================================================
#
#                                  MAIN
#
# =============================================================================

    
# parse commandline
opts = parse_commandline()

# access configuration file
cp = ConfigParser.ConfigParser()
cp.read(opts.ini_file)

home = os.environ['HOME']
user = os.environ['USER']

if opts.verbose:
  print "checking the parameters..."

############################################################################
# check necessary txt files
# if not exist, download
############################################################################
inputfiles = {}
if not os.path.isdir("inputfiles"): os.mkdir("inputfiles")

for f in ("vstyle.css","S6_channel_list.txt","ER7_channel_list.txt","O1_channel_list.txt,O2_channel_list.txt"):
  if not os.path.isfile("inputfiles/%s"%f):
    inputfile = "https://raw.githubusercontent.com/mcoughlin/line_search/master/inputfiles/%s"%f
    outfile = os.path.join("inputfiles",f)
    exit = os.system("wget -O %s %s"%(outfile,inputfile))
    if exit > 0:
      print >> sys.stderr, "Error: could not download %s. Please check the address."%cp.get("input","veto_definer_file")
      sys.exit(1)

############################################################################
# check config and make sure they are sane
############################################################################

########################### [general] section ##############################

if cp.get("general","tag").find("-") is not -1:
    print >> sys.stderr, 'Error: you can not use "-" in your tag'
    sys.exit(1)

if cp.get("general","tag")=="":
    from time import strftime, localtime
    cp.set("general","tag",strftime("%y%m%d",localtime()))
    
if os.path.isdir("dags"): 
    KW_veto_utils.rename("dags")
os.makedirs("dags")
    
    
########################### [condor] section ###############################

# log directory - set it to /usr1/${USER} if left blank in param file
#                 otherwise set as specified
if cp.get("condor", "logdir")=="":
    cp.set("condor","logdir","/usr1/%s"%user)
else:
    # print precaution message
    print >> sys.stderr, """
********************************************************************************
You might need to tell Condor not to complain that your DAG logs are on 
NFS volumes before submitting your DAG.

bash users:
export _CONDOR_DAGMAN_LOG_ON_NFS_IS_ERROR=FALSE

tcsh users:
setenv _CONDOR_DAGMAN_LOG_ON_NFS_IS_ERROR FALSE
********************************************************************************
    """
if cp.get("condor", "scratchdir")=="":
    cp.set("condor","scratchdir","/usr1/%s"%user)

for bin in ("pycoh_seed","line_search","post_pycoh","db_maker","post_db_maker"):
  if not os.path.isfile(cp.get("condor","%s-bin"%bin)):
    print >> sys.stderr, "Error: %s-bin not found"%bin
    sys.exit(1)
    
    
if cp.get("condor","retry")=="":
    print >> sys.stderr, """
    retry is not set in param file.
    setting retry to 1
    """
    cp.set("condor","retry","1")

try:
  cp.getint("condor","retry")
except ValueError:
  raise('Error: retry must be an int value')
    
####################### [data_conditioning] section ########################

if cp.get("data_conditioning","threshold")=="":
  print >> sys.stderr, "Error: threshold must be specified."
  sys.exit(1)

try:
  cp.getfloat("data_conditioning","threshold")
except ValueError:
  raise("Error: threshold must be float number.")


######################### [output] section #################################

# if not specified, set the output to "results"
if cp.get("output","out_dir")=="": 
  cp.set("output","out_dir","results")
    
# if output directory already exists, rename to avoid collision;
# create output directory if not exist yet
KW_veto_utils.rename(cp.get("output","out_dir"))
if not os.path.isdir(cp.get("output","out_dir")): 
  os.makedirs(cp.get("output","out_dir"))
    
        
############################# [input] section #################################

# convert to upper case if not already
cp.set("input", "ifo", cp.get("input", "ifo").upper())
if cp.get("input", "ifo") not in ("H1", "H2", "L1", "V1"):
  print >> sys.stderr, "%s is not a supported ifo."%cp.get("input", "ifo")
  sys.exit(1)

# check if necessary input exists
for f in ("pycoh_ini", "analyzed_seg_files", "channel_list_file"):
  if cp.get("input",f)=="":
    print >> sys.stderr, "Error: %s is required in param file"%f
    sys.exit(1)
    if not os.path.isfile(cp.get("input",f)):
      print >> sys.stderr, "Error: --%s %s not found"%(f,cp.get(input,f))
      sys.exit(1)

if cp.get("input","channel_list_file")[:4] == "http":
  chanFile = urllib2.urlopen(cp.get("input","channel_list_file"))
else:
  try:
    chanFile = open(cp.get("input","channel_list_file"))
  except:
    print >> sys.stderr, "Error: cannot read the channel_list_file."
    raise

channel_list = [f.strip().upper() for f in cp.get("input","channels").split(",")]

## read available channels
if cp.get("input","ifo") == "H1":
  ok_channel = [line.strip() for line in chanFile.readlines() if re.match("H0", line.upper()) != None or re.match("H1",line.upper()) != None or re.match("S5",line.upper()) != None]
if cp.get("input","ifo") == "H2":
  ok_channel = [line.strip() for line in chanFile.readlines() if re.match("H0", line.upper()) != None or re.match("H2",line.upper()) != None or re.match("S5",line.upper()) != None]
if cp.get("input","ifo") == "L1":
  ok_channel = [line.strip() for line in chanFile.readlines() if re.match("L0", line.upper()) != None or re.match("L1",line.upper()) != None or re.match("S5",line.upper()) != None]
if cp.get("input", "ifo") == "V1":
  ok_channel = [line.strip() for line in chanFile.readlines() if re.match("V1", line.upper()) != None]

# if blank, use all the channels available
if channel_list == [""]:
  channel_list = ok_channel
else: # otherwise, check if specified channel names are available in the file
  for c in channel_list:
    if c not in ok_channel:
      print >> sys.stderr, "Error: channel name %s is not in channel_list_file %s."%(c,cp.get("input","channel_list_file"))
      sys.exit(1)

# exclude channels specified in "exclude_channels"
ex_chan=[f.strip() for f in cp.get("input","exclude_channels").split(",")]
if ex_chan != [""]:
  for ec in ex_chan:
    channel_list.remove(ec)

if opts.verbose:
  print "channels to be analyzed:"
  print  channel_list

# get categories to apply
cats = {}
for i in range(5):
  i += 1 # cat start from 1
  try:
    cats[i]=cp.getboolean("input","cat%d"%i)    
  except:
    print >> sys.stderr, "cat%s has to be True or False"%i  
    raise

# if at least one of them is True, check server and veto_defiver_file
if any(cats.values()) == True:
  if cp.get("input","veto_definer_file") == "":
    print >> sys.stderr, "Error: you need to specify veto_definer_file."
  # if http, copy it over
  if cp.get("input","veto_definer_file").startswith("http"):
    outfile = os.path.join("inputfiles",os.path.basename(cp.get("input","veto_definer_file")))
    cmd = "wget -O %s %s"%(outfile,cp.get("input","veto_definer_file"))
    exit = os.system(cmd)
    if exit > 0:
      print >> sys.stderr, "Error: could not download %s. Please check the address."%cp.get("input","veto_definer_file")
      sys.exit(1)
    cp.set("input","veto_definer_file",outfile)
    if opts.verbose:
      print "veto cat files retrieved."
  else:
    if not os.path.isfile(os.get("input","veto_definer_file")):
      print >> sys.stderr, "Error: veto_definer_file %s not found"%cp.get("input","veto_definer_file")

  # check the server
  if cp.get("input","server") == "":
    cp.set("input","server","https://segdb.ligo.caltech.edu")
  if cp.get("input","server").startswith("https://"):
    cmd_ping = "ligolw_segment_query --ping --segment-url %s"%cp.get("input","server")
    if os.system(cmd_ping) > 0:
      print >> sys.stderr, "Error: problem with segment server. Please check %s works."%cmd_ping
      sys.exit(1)


########################## [plot] [webpage] section ###########################

# check if boolean values are readable
# zip represents (section, item) in config parser
for i in (("plot","plot"),("webpage","webpage")):
  try:
    cp.getboolean(i[0],i[1])
  except ValueError:
    raise("""
    Error: "%s" in param file must be one of "true", "yes",
           "on", or "0" to indicate True, "false", "no", "off", or "1" to 
           indicate False. Those are case insensitive.""")%i[1]

    
# if not specified, set output directory of webpages to
# ${HOME}/public_html/veto/(tag)_webpage
if cp.get("webpage", "outdir")=="":
  cp.set("webpage","outdir","%s/public_html/veto/"%home)
web_outdir = os.path.join(cp.get("webpage","outdir"),"%s_webpage"%cp.get("general","tag"))

# make output directory
if not os.path.isdir(cp.get("webpage","outdir")):
  os.makedirs(cp.get("webpage","outdir"))
    

  # if webpage is true, then set output of plots to a subdirectory of 
  # webpage output, so that the code doesn't need to copy over
  # print warning message
if cp.getboolean("webpage","webpage"):
  if cp.getboolean("plot","plot") and cp.get("plot","outdir") != os.path.join(web_outdir,"plots"):
    cp.set("plot","outdir",os.path.join(web_outdir,"plots"))
    print >> sys.stderr, """
    Warning: plot output directory in param file is ignored.
             plot output will be in:
             %s
    """%cp.get("plot","outdir")
     
# if not specified, set output dir of plots to plots
if cp.getboolean("plot","plot"):
  if cp.get("plot","outdir")=="":
    cp.set("plot","outdir","plots")
  # make output directory 
  KW_veto_utils.rename(cp.get("plot","outdir"))
  os.makedirs(cp.get("plot","outdir"))
 

########################## show parameters #################################
if opts.verbose:
  for s in cp.sections():
    print s+":"
    for i in cp.items(s):
      print i
    print
            
############################################################################
# get analyze segments
############################################################################

start_time,duration,segment_file = get_analyze_segment()

# make output directory 
if cp.getboolean("plot","plot"):
    plot_outdir = cp.get("plot","outdir")
    if not os.path.isdir(plot_outdir): os.makedirs(plot_outdir)

###########################################################################
# prepare pycoh
###########################################################################

# run 20 channel at a time
i = 0
while i * 20 < len(channel_list):
  i += 1
  tag = "%s_pycoh_%d"%(cp.get("general","tag"),i)
  pycoh_dir = os.path.abspath(tag)
  if not os.path.isdir(pycoh_dir):
    os.makedirs(pycoh_dir)
  pycoh_ini_name = os.path.join(pycoh_dir,"pycoh.ini")
  copied_seg = os.path.join(pycoh_dir,os.path.basename(segment_file))
  shutil.copy(segment_file, copied_seg)
  write_pycoh_ini(cp.get("input","ifo"), tag, cp.get("input","pycoh_ini"), pycoh_ini_name, copied_seg, channel_list[(i-1)*20:i*20],cp.get("condor","scratchdir"))
  run_seed(tag,pycoh_ini_name,pycoh_dir)

############################################################################
# set up DAG
############################################################################

if opts.verbose: print "creating dag files..."
dag_maker(i)

##################### print informational message ##########################

dag_prefix = os.path.join("dags",cp.get("general","tag"))

print """
********************************************************************************
Ready to run the dag file!
To run:
$ condor_submit_dag -maxjobs (reasonable number) %s.dag
To check the status:
$ tail -f %s.dag.dagman.out

*Always* set maxjobs.
********************************************************************************
"""%(dag_prefix,dag_prefix)

